{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 12\n",
    "\n",
    "Using section 8.4 in Deep Learning with Python as a guide, implement a variational autoencoder using the MNIST data set and save a grid of 15 x 15 digits to the results/vae directory. If you would rather work on a more interesting dataset, you can use the CelebFaces Attributes Dataset instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build VAE encoder network\n",
    "\n",
    "img_shape = (28, 28, 1)\n",
    "batch_size = 16\n",
    "latent_dim = 2\n",
    "\n",
    "input_img = keras.Input(shape = img_shape)\n",
    "\n",
    "x = layers.Conv2D(32, 3, padding = 'same', activation = 'relu')(input_img)\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding = 'same', activation = 'relu', strides = (2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding = 'same', activation = 'relu')(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding = 'same', activation = 'relu')(x)\n",
    "\n",
    "shape_before_flattening = K.int_shape(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(32, activation = 'relu')(x)\n",
    "\n",
    "# encode input image into parameters\n",
    "z_mean = layers.Dense(latent_dim)(x)\n",
    "z_log_var = layers.Dense(latent_dim)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent-space-sampling function\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape = (K.shape(z_mean)[0], latent_dim), mean = 0., stddev = 1.)\n",
    "    \n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build VAE decoder network, mapping latent space points to images\n",
    "\n",
    "decoder_input = layers.Input(K.int_shape(z)[1:]) # feed in z\n",
    "\n",
    "# upsample input\n",
    "x = layers.Dense(np.prod(shape_before_flattening[1:]), activation = 'relu')(decoder_input)\n",
    "\n",
    "# reshape z into feature map same shape as feature map before flattening in encoder\n",
    "x = layers.Reshape(shape_before_flattening[1:])(x)\n",
    "\n",
    "# decode z into feature map same as original image\n",
    "x = layers.Conv2DTranspose(32, 3, padding = 'same', activation = 'relu', strides = (2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(1, 3, padding = 'same', activation = 'sigmoid')(x)\n",
    "\n",
    "# instantiate decoder model (turn input into decoded image)\n",
    "decoder = Model(decoder_input, x)\n",
    "\n",
    "# recover decoded z\n",
    "z_decoded = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom layer to compute VAE loss\n",
    "\n",
    "class CustomVariationalLayer(keras.layers.Layer):\n",
    "    \n",
    "    def vae_loss(self, x, z_decoded):\n",
    "        x = K.flatten(x)\n",
    "        z_decoded = K.flatten(z_decoded)\n",
    "        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
    "        k1_loss = -5e-4 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis = -1)\n",
    "        \n",
    "        return K.mean(xent_loss + k1_loss)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        z_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, z_decoded)\n",
    "        self.add_loss(loss, inputs = inputs)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "y = CustomVariationalLayer()([input_img, z_decoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 32)   320         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 14, 14, 64)   18496       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 14, 14, 64)   36928       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 14, 14, 64)   36928       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12544)        0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           401440      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            66          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            66          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2)            0           dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "functional_5 (Functional)       (None, 28, 28, 1)    56385       lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "custom_variational_layer_5 (Cus (None, 28, 28, 1)    0           input_7[0][0]                    \n",
      "                                                                 functional_5[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 550,629\n",
      "Trainable params: 550,629\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:3349: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 3665s 977ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "  62/3750 [..............................] - ETA: 4:39:34 - loss: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "# train vae\n",
    "\n",
    "vae = Model(input_img, y)\n",
    "vae.compile(optimizer = 'rmsprop', loss = None)\n",
    "vae.summary()\n",
    "\n",
    "(x_train, _), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape(x_test.shape + (1,))\n",
    "\n",
    "vae.fit(x = x_train,\n",
    "        y = None,\n",
    "       shuffle = True,\n",
    "       epochs = 10,\n",
    "       batch_size = batch_size,\n",
    "       validation_data = (x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot grid of decoded images from 2D latent space \n",
    "\n",
    "n = 15\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = norm.ppf(np.linespace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linespace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([xi, yi])\n",
    "        z_sample = np.title(z_sample, batch_size).reshape(batch_size, 2)\n",
    "        x_decoded = decoder.predict(z_sample, batch_size = batch_size)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "              j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.imgshow(figure, cmap = 'Greys_r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
