{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 11\n",
    "\n",
    "Using section 8.1 in Deep Learning with Python as a guide, implement an LSTM text generator. Train the model on the Enron corpus or a text source of your choice. Save the model and generate 20 examples to the results directory of dsc650/assignments/assignment11/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "import random\n",
    "import sys\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length:  581889\n"
     ]
    }
   ],
   "source": [
    "# Load 'Adventures of Sherlock Holmes' data \n",
    "# data is located in assignment folder or can be optained from https://www.gutenberg.org/ebooks/1661 downloaded as \"Plain Text UTF-8\"\n",
    "\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "path = os.path.join(current_dir, 'sherlock_holmes.txt')\n",
    "\n",
    "# Read data as lowercase\n",
    "\n",
    "text = open(path).read().lower()\n",
    "\n",
    "print('Corpus length: ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "\n",
    "results_dir = current_dir.joinpath('results')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044424d518c54594bc13e1db2af2336b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/193943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences:  193943\n",
      "Unique characters:  73\n",
      "Vectorization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5696961fac114382a552baf295500cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization Complete.\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data\n",
    "\n",
    "maxlen = 60\n",
    "step = 3\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in tqdm(range(0, len(text) - maxlen, step)):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print('Number of sequences: ', len(sentences))\n",
    "\n",
    "# Create list of unique characters\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "print('Unique characters: ', len(chars))\n",
    "\n",
    "# Create dictionary to map unique characters to index\n",
    "\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# One-hhoht encode characters into binary arrays\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype = np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype = np.bool)\n",
    "\n",
    "for i, sentence in tqdm(enumerate(sentences)):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "print('Vectorization Complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape = (maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'Adam')\n",
    "\n",
    "# Save the model\n",
    "model.save('results/text_generation_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample next character based on predictions\n",
    "\n",
    "def sample(preds, temperature = 1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329e5a8ef8034e0a91c832251234976a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1\n",
      "1516/1516 [==============================] - 249s 165ms/step - loss: 2.5463\n",
      "--- Generating with seed: \"to him.\n",
      "\n",
      "“well, have you solved it?” i asked as i entered.\n",
      "\n",
      "\"\n",
      "epoch  2\n",
      "1516/1516 [==============================] - 231s 152ms/step - loss: 2.1971\n",
      "--- Generating with seed: \"hey had locked.\n",
      "\n",
      "“i am naturally observant, as you may have \"\n",
      "epoch  3\n",
      "1516/1516 [==============================] - 228s 150ms/step - loss: 2.0840\n",
      "--- Generating with seed: \" the front door,” cried holmes, and we all rushed down the\n",
      "s\"\n",
      "epoch  4\n",
      "1516/1516 [==============================] - 229s 151ms/step - loss: 2.0086\n",
      "--- Generating with seed: \"lem of the grosvenor square furniture van.\n",
      "that is quite cle\"\n",
      "epoch  5\n",
      "1516/1516 [==============================] - 231s 153ms/step - loss: 1.9487\n",
      "--- Generating with seed: \"d\n",
      "there are many noble families to whom we have advanced lar\"\n",
      "epoch  6\n",
      "1516/1516 [==============================] - 230s 152ms/step - loss: 1.8983\n",
      "--- Generating with seed: \"s to their nature,” he answered.\n",
      "\n",
      "“then what are they? who i\"\n",
      "epoch  7\n",
      "1516/1516 [==============================] - 231s 152ms/step - loss: 1.8545\n",
      "--- Generating with seed: \"e before the altar.”\n",
      "\n",
      "“perhaps, mrs. moulton, you would like\"\n",
      "epoch  8\n",
      "1516/1516 [==============================] - 230s 152ms/step - loss: 1.8149\n",
      "--- Generating with seed: \"rom the dead man’s lap, and\n",
      "throwing the noose round the rep\"\n",
      "epoch  9\n",
      "1516/1516 [==============================] - 231s 152ms/step - loss: 1.7819\n",
      "--- Generating with seed: \"ned to his desk and, unlocking it, drew out a small\n",
      "case-boo\"\n",
      "epoch  10\n",
      "1516/1516 [==============================] - 235s 155ms/step - loss: 1.7521\n",
      "--- Generating with seed: \"e paced up and down in front of briony lodge, waiting for th\"\n",
      "epoch  11\n",
      "1516/1516 [==============================] - 232s 153ms/step - loss: 1.7259\n",
      "--- Generating with seed: \" frightened and ran\n",
      "out again. oh, it is so dreadfully still\"\n",
      "epoch  12\n",
      "1516/1516 [==============================] - 233s 153ms/step - loss: 1.7015\n",
      "--- Generating with seed: \"atever\n",
      "it was i gave him without question, land, money, hous\"\n",
      "epoch  13\n",
      "1516/1516 [==============================] - 239s 158ms/step - loss: 1.6802\n",
      "--- Generating with seed: \"not have a farthing from me,’ i cried, on which he bowed and\"\n",
      "epoch  14\n",
      "1516/1516 [==============================] - 233s 154ms/step - loss: 1.6608\n",
      "--- Generating with seed: \"in saying that the flooring and walls are\n",
      "sound, and that th\"\n",
      "epoch  15\n",
      "1516/1516 [==============================] - 234s 155ms/step - loss: 1.6421\n",
      "--- Generating with seed: \"the dregs of the docks, breathing in the poison\n",
      "or sleeping \"\n",
      "epoch  16\n",
      "1516/1516 [==============================] - 235s 155ms/step - loss: 1.6249\n",
      "--- Generating with seed: \" know, and my poor\n",
      "little reputation, such as it is, will su\"\n",
      "epoch  17\n",
      "1516/1516 [==============================] - 234s 154ms/step - loss: 1.6095\n",
      "--- Generating with seed: \" course, one can’t refuse a lady, and such a very positive o\"\n",
      "epoch  18\n",
      "1516/1516 [==============================] - 245s 161ms/step - loss: 1.5943\n",
      "--- Generating with seed: \"per, but i think, watson, that we shall be able to strike\n",
      "de\"\n",
      "epoch  19\n",
      "1516/1516 [==============================] - 247s 163ms/step - loss: 1.5811\n",
      "--- Generating with seed: \"lowed them from\n",
      "the cellar, “i do not know how the bank can \"\n"
     ]
    }
   ],
   "source": [
    "# Fit model and text gerenation\n",
    "\n",
    "for epoch in tqdm(range(1, 20)):\n",
    "    print('epoch ', epoch)\n",
    "    model.fit(x, y, batch_size = 128, epochs = 1)\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "    \n",
    "    f = open(\"results/text_example{}.txt\".format(epoch), \"w+\")\n",
    "    f.write('--- Generating with seed: \"' + generated_text + '\"\\n')\n",
    "    \n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        f.write('------ temperature: ' + str(temperature) + '\\n')\n",
    "        f.write(generated_text + '\\n')\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1\n",
    "                \n",
    "            preds = model.predict(sampled, verbose = 0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "            \n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "            \n",
    "            f.write(next_char)\n",
    "        f.write('\\n')   \n",
    "    f.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
